{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment topic classification with Google's Universal Sentence Encoder\n",
    "\n",
    "![Universal Sentence Encoder](https://www.gstatic.com/aihub/tfhub/universal-sentence-encoder/example-similarity.png)\n",
    "https://tfhub.dev/google/universal-sentence-encoder/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing text documents (has to have column 'Text')\n",
    "source_file = \"TUI_Comments.csv\"\n",
    "text_column = \"NPSReason\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0330 23:34:59.146178  6972 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#import os\n",
    "\n",
    "#import re\n",
    "#import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Universal Sentence Encoder model\n",
    "* Use \"https://tfhub.dev/google/universal-sentence-encoder/2\" to import the quick (but less accurate) model\n",
    "* Use \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" to import the most accurate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in verbatim file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_documents = pd.read_csv(source_file, na_values=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process text documents through the encoder and get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    \"\"\"\n",
    "    Feed in a vector of texts, return a data frame of embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    text = text.values.tolist()\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings = session.run(embed(text))\n",
    "    return embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform spectral clustering of embeddings\n",
    "https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(embeddings, n_classes=5):\n",
    "    \"\"\"\n",
    "    Feed in a data frame of embeddings, return a vector of classes\n",
    "    \"\"\"\n",
    "    \n",
    "    clusters = SpectralClustering(n_clusters=n_classes, assign_labels=\"discretize\", \n",
    "                                  random_state=0).fit(embeddings)\n",
    "    return clusters.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of the most common unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(text, n_words=100):\n",
    "    \"\"\"\n",
    "    Feed in a text column, return a list of top n words based on their frequency\n",
    "    \"\"\"\n",
    "    \n",
    "    vec = CountVectorizer().fit(text)\n",
    "    bag_of_words = vec.transform(text)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare embeddings using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(cluster_emb, unigram_emb):\n",
    "    \"\"\"\n",
    "    Feed in averaged cluster embeddings and a data frame containing embeddings for all unigrams\n",
    "    Return cosine similarities\n",
    "    \"\"\"\n",
    "    \n",
    "    cosine_sim = []\n",
    "    unigram_count = unigram_emb.shape[0]\n",
    "    for u in range(unigram_count):\n",
    "        cosine_sim.append(cosine_similarity(cluster_emb.values.reshape(1, -1),\n",
    "                                           unigram_emb[u].reshape(1, -1))[0][0])\n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select unigrams with highest cosine similarity to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_unigrams(unigrams, cosine_sim, n=1):\n",
    "    \"\"\"\n",
    "    Feed in a list of unigrams and their similarity scores\n",
    "    Return top n words that best match the cluster centre\n",
    "    \"\"\"\n",
    "    \n",
    "    cbind = pd.concat([pd.DataFrame(unigrams), pd.DataFrame(cosine_sim, columns = ['Sim'])], axis=1)\n",
    "    return cbind.sort_values('Sim', ascending = False)['Word'].head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign unigrams as names to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_clusters(n_clusters, text_documents, text_column):\n",
    "    \"\"\"\n",
    "    Feed in a list of unigrams and their similarity scores\n",
    "    Return top n words that best match the cluster centre\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_names = []\n",
    "    for i in range(n_clusters):\n",
    "        matching_comments = text_documents[document_clusters == i][text_column]\n",
    "        top_words = pd.DataFrame(get_top_n_words(matching_comments), columns = ['Word', 'N'])\n",
    "        word_embeddings = get_embeddings(top_words['Word'])\n",
    "        cosine_sim = compare_embeddings(centroids.iloc[i,:], word_embeddings)\n",
    "        cluster_names.append(best_unigrams(top_words['Word'], cosine_sim).values[0])\n",
    "    return cluster_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0331 00:21:54.441677  6972 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# process documents through the encoder and get embeddings\n",
    "document_embeddings = get_embeddings(text_documents[text_column])\n",
    "\n",
    "# cluster embeddings\n",
    "document_clusters = spectral_clustering(document_embeddings)\n",
    "\n",
    "# calculate centres of clusters\n",
    "centroids = pd.DataFrame(document_embeddings).groupby(document_clusters).mean()\n",
    "\n",
    "# generate names for clusters\n",
    "cluster_names = name_clusters(centroids.shape[0], text_documents=text_documents, text_column=text_column) \n",
    "\n",
    "# match cluster names back to documents\n",
    "cluster_lookup = pd.concat([pd.DataFrame(list(range(centroids.shape[0]))), pd.DataFrame(cluster_names)], axis=1)\n",
    "classified_documents = pd.concat([text_documents, pd.Series(document_clusters).map(cluster_lookup.to_dict()[0])], axis=1)\n",
    "classified_documents = classified_documents.rename(columns={0:'Topic'})\n",
    "\n",
    "# save the output\n",
    "classified_documents.to_csv(\"Classified documents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_SNE wih names overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_comments = pd.concat([sample_comments['NPSReason'], pd.DataFrame(message_embeddings)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. assign a tag to a comment\n",
    "4. calculate embedding for tag\n",
    "5. compare results\n",
    "6. assign tags based on similarities to other comments\n",
    "7. emulate the app behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D mapping with t-SNE\n",
    "https://lvdmaaten.github.io/tsne/\n",
    "\n",
    "https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X = sample_comments.iloc[:, 1:513]\n",
    "X_embedded = TSNE(n_components=2, metric='cosine').fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# We import seaborn to make nice plots.\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=0, y=1, data=df, hue=spectral.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
